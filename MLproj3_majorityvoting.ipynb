{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the actual and predicted labels for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = genfromtxt('actual.csv', delimiter=',')\n",
    "logistic = genfromtxt('logistic.csv', delimiter=',')\n",
    "cnn = genfromtxt('cnn.csv', delimiter=',')\n",
    "dnn = genfromtxt('dnn.csv', delimiter=',')\n",
    "svm = genfromtxt('svm.csv', delimiter=',')\n",
    "rf = genfromtxt('rf.csv', delimiter=',')\n",
    "\n",
    "actual_usps = genfromtxt('actual_usps.csv', delimiter=',')\n",
    "logistic_usps = genfromtxt('logistic_usps.csv', delimiter=',')\n",
    "cnn_usps = genfromtxt('cnn_usps.csv', delimiter=',')\n",
    "dnn_usps = genfromtxt('dnn_usps.csv', delimiter=',')\n",
    "svm_usps = genfromtxt('svm_usps.csv', delimiter=',')\n",
    "rf_usps = genfromtxt('rf_usps.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining the predictions of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_predicted = []\n",
    "for i in range(len(logistic)):\n",
    "    row = [int(logistic[i]),int(cnn[i]),int(dnn[i]),int(svm[i]),int(rf[i])]\n",
    "    most_common,num_most_common = Counter(row).most_common(1)[0]\n",
    "    combined_predicted.append(most_common)\n",
    "\n",
    "\n",
    "combined_predicted_usps = []\n",
    "for i in range(len(logistic_usps)):\n",
    "    row = [int(logistic_usps[i]),int(cnn_usps[i]),int(dnn_usps[i]),int(svm_usps[i]),int(rf_usps[i])]\n",
    "    most_common,num_most_common = Counter(row).most_common(1)[0]\n",
    "    combined_predicted_usps.append(most_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the combined predictions and actual values to calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined accuracy using majority voting:  0.9753\n",
      "Confusion matrix:\n",
      "[[ 978    0    5    1    0    1    1    0    2    0]\n",
      " [   0 1128    0    1    0    2    2    2    3    0]\n",
      " [   6    0  995    5    0    1    3    1    6    1]\n",
      " [   1    1    7  994    0    6    2    2    3    0]\n",
      " [   1    1    3    0  964    0    3    1    2   11]\n",
      " [   4    0    2   10    0  857    6    1    5    3]\n",
      " [   7    2    2    1    2    1  941    0    3    0]\n",
      " [   3    4    8    2    3    1    0 1009    3   11]\n",
      " [   3    0    5    6    4    4    4    3  928    3]\n",
      " [   5    5    1   10   11    2    0    4    6  959]]\n",
      "Combined accuracy for USPS using majority voting:  0.44107205360268015\n",
      "Confusion matrix:\n",
      "[[ 639    2  342   43  285  158   65   51   50  365]\n",
      " [ 121  512  201  161  284  109   25  507   65   15]\n",
      " [ 118   11 1501   73   37  111   54   56   31    7]\n",
      " [  57    1  141 1395   12  296    4   48   38    8]\n",
      " [  20   80   48   25 1205  157   18  192  177   78]\n",
      " [  99   14  188  110   21 1445   53   36   26    8]\n",
      " [ 217   12  398   45   85  301  877   13   20   32]\n",
      " [  69  195  346  384   43  157   16  645  130   15]\n",
      " [ 133   21  163  257   92  755   86   64  383   46]\n",
      " [  20  148  166  383  163  105    6  500  290  219]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def calculate_accuracy(x,y):\n",
    "    count = 0\n",
    "    for i in range(len(y)):\n",
    "        if x[i] == y[i]:\n",
    "            count+=1\n",
    "    accuracy = count/float(len(y))\n",
    "    return accuracy\n",
    "\n",
    "accuracy = calculate_accuracy(combined_predicted,actual)\n",
    "print(\"Combined accuracy using majority voting: \",accuracy)\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(actual, combined_predicted))\n",
    "\n",
    "accuracy_usps = calculate_accuracy(combined_predicted_usps,actual_usps)\n",
    "print(\"Combined accuracy for USPS using majority voting: \",accuracy_usps)\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(actual_usps, combined_predicted_usps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
